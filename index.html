<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talking Head - MP3 Example</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">


    <style>
        body, html {
            width: 100%;
            height: 100%;
            margin: 0;
            padding: 0;
            color: white;
        }

        #avatar {
            display: block;
            position: absolute;
            top: 0;
            left: 0;
            width: 40%;
            height: 100%;
        }

        @media (max-width: 768px) {
            #avatar {
                display: none;
            }
        }

        #video-section {
            position: absolute;
            top: 0;
            left: 40%;
            right: 0;
            height: 70%;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #controlsection {
            display: flex;
            flex-direction: column;
            gap: 10px;
            position: absolute;
            left: 40%;
            height: 30%;
            right: 0;
            bottom: 0;
            padding: 20px;
            color: black;
        }

        #load {
            font-family: Arial;
            font-size: 20px;
        }

        #json {
            flex: 1;
            background-color: lightgray;
            font-family: Arial;
            font-size: 20px;
        }

        #loading {
            display: block;
            position: absolute;
            top: 50px;
            left: 50px;
            width: 200px;
            font-family: Arial;
            font-size: 20px;
        }
    </style>
    <script type="importmap">
    { "imports":
      {
        "three": "https://cdn.jsdelivr.net/npm/three@0.161.0/build/three.module.js/+esm",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.161.0/examples/jsm/",
        "talkinghead": "./js/talkinghead.mjs"
      }
    }
    </script>
    <script type="module">
        import { TalkingHead } from "talkinghead";
    
        let head; // TalkingHead instance
        let audio; // Audio object
        let video; // Video element
    
        // New function to load audio from local JSON file
        async function loadAudioFromLocal() {
            try {
                const nodeJSON = document.getElementById('json');
                nodeJSON.value = "Please wait...";

                const response = await fetch('./transcript/transcript.json')
                if (response.ok) {
                    const json = await response.json();
                    nodeJSON.value = JSON.stringify(json, null, 4);


                    // Parse JSON
                    console.log("Type of JSON:", typeof json);

                    // Debugging
                    console.log("Words from JSON:", json.words);

                    if (json.words && json.words.length) {
                        // TalkingHead audio object
                        audio = {
                            audio: null, // We don't have audio buffer here
                            words: [],
                            wtimes: [],
                            wdurations: [],
                            markers: [],
                            mtimes: []
                        };

                        // Add words to the audio object
                        json.words.forEach(x => {
                            audio.words.push(x.word);
                            audio.wtimes.push(1000 * x.start - 150);
                            audio.wdurations.push(1000 * (x.end - x.start));
                        });

                        // Callback function to make the avatar look at the camera
                        const startSegment = async () => {
                            head.lookAtCamera(500);
                            head.speakWithHands();
                        };

                        // Add timed callback markers to the audio object
                        json.segments.forEach(x => {
                            if (x.start > 2 && x.text.length > 10) {
                                audio.markers.push(startSegment);
                                audio.mtimes.push(1000 * x.start - 1000);
                            }
                        });

                        console.log("Audio object created from local JSON:", audio);
                    }
                };
            } catch (error) {
                console.error("Error in loadAudioFromLocal:", error);
                nodeJSON.value = 'Error: ' + error.message;
            }
        }
    
        document.addEventListener('DOMContentLoaded', async function(e) {

            // Initialize video element
            // disable controls
            video = document.getElementById('videoPlayer');
            video.controls = false;

            const nodeAvatar = document.getElementById('avatar');
            head = new TalkingHead( nodeAvatar, {
                ttsEndpoint: "https://eu-texttospeech.googleapis.com/v1beta1/text:synthesize",
                lipsyncModules: ["en", "fi"],
                cameraView: "mid",
                cameraRotateEnable: false,
            });
      
            // Load and show the avatar
            const nodeLoading = document.getElementById('loading');
            try {
                // Fetch the transcript JSON automatically when the head is loading
                await loadAudioFromLocal();


                await head.showAvatar( {
                    url: 'https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&textureSizeLimit=1024&textureFormat=png',
                    body: 'F',
                    avatarMood: 'happy',
                    lipsyncLang: 'en'
                }, (ev) => {
                    if ( ev.lengthComputable ) {
                    let val = Math.min(100,Math.round(ev.loaded/ev.total * 100 ));
                    nodeLoading.textContent = "Loading " + val + "%";
                    }
                });
                nodeLoading.style.display = 'none';
                video.controls = true;// Enable video controls
            }catch (error) {
                console.log(error);
                nodeLoading.textContent = error.toString();
            }

            let lastPlayedTime = 0;

            
            video.addEventListener('seeking', function() {
                head.stopSpeaking();
                console.log("Video seeking");
            });


            video.addEventListener('seeked', function() {
                  const seekTime = video.currentTime * 1000;
                  const startIndex = findNearestWordIndex(seekTime);
                  const segment = createAudioSegment(startIndex);
                  head.speakWithoutAudio(segment);
                  console.log("Video seeked to " + video.currentTime + "s, resuming lip sync");
                  console.log("startIndex: " + startIndex);
            });


            
            video.addEventListener('play', function() {
              if (lastPlayedTime > 0) {
                  head.resumeAll();
                  console.log("Video and lip sync resumed");
              } else {
                  head.speakWithoutAudio(audio);
                  console.log("Video played, starting lip sync");
              }
            });

            video.addEventListener('pause', function() {
                  head.pauseAll();
                  console.log("Video paused");
            });
            video.addEventListener('timeupdate', function() {
                lastPlayedTime = video.currentTime;
            });
            function findNearestWordIndex(seekTime) {
                return audio.wtimes.findIndex(time => time >= seekTime);
            }
            function createAudioSegment(startIndex) {
                return {
                    words: audio.words.slice(startIndex),
                    wtimes: audio.wtimes.slice(startIndex).map(time => time - audio.wtimes[startIndex]),
                    wdurations: audio.wdurations.slice(startIndex),
                    markers: audio.markers.slice(startIndex),
                    mtimes: audio.mtimes.slice(startIndex).map(time => time - audio.wtimes[startIndex])
                };
            }
        });
    </script>
</head>
<body class="min-h-screen bg-white flex flex-col items-center justify-center p-4">
    <!-- Avatar Section -->
    <div id="avatar" class="bg-gray-100">
        <!-- Avatar content can go here -->
    </div>

    <div class="flex flex-col items-center justify-center space-y-4">
      <!-- Video Section -->
      <div id="video-section" class="bg-gray-200">
          <video id="videoPlayer" class="h-full w-auto" controls controlsList="noplaybackrate nodownload" disablePictureInPicture>
              <source src="./media/final_video.mp4" type="video/mp4">
              Your browser does not support the video tag.
          </video>
      </div>
      <!-- Controls Section -->
      <div id="controlsection" class="bg-gray-50 p-8 space-y-6">
        <div>
            <label for="json" class="block text-sm font-medium text-gray-700 mb-2">JSON Output</label>
            <textarea id="json" readonly class="w-full h-32 text-sm text-gray-500 border border-gray-300 rounded-md focus:ring-custom-accent focus:border-custom-accent p-3 resize-none bg-white shadow-inner"></textarea>
        </div>
      </div>
    </div>
    
    <!-- Loading Indicator -->
    <div id="loading" class="mt-4 w-full max-w-md text-center text-sm text-gray-500">
        <!-- Loading indicator can go here -->
    </div>
</body>
</html>
